(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[2784],{3180:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/references/stable_baselines_3",function(){return n(145)}])},6408:function(e,t,n){"use strict";var a=n(1527);n(959);let s={logo:(0,a.jsx)("span",{children:"NetAIGym"}),project:{link:"https://github.com/pinyaras/GMAClient"},chat:{link:"https://netai-gym.slack.com",icon:(0,a.jsx)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"20",height:"20",fill:"currentColor",viewBox:"0 0 16 16",children:(0,a.jsx)("path",{d:"M3.362 10.11c0 .926-.756 1.681-1.681 1.681S0 11.036 0 10.111C0 9.186.756 8.43 1.68 8.43h1.682v1.68zm.846 0c0-.924.756-1.68 1.681-1.68s1.681.756 1.681 1.68v4.21c0 .924-.756 1.68-1.68 1.68a1.685 1.685 0 0 1-1.682-1.68v-4.21zM5.89 3.362c-.926 0-1.682-.756-1.682-1.681S4.964 0 5.89 0s1.68.756 1.68 1.68v1.682H5.89zm0 .846c.924 0 1.68.756 1.68 1.681S6.814 7.57 5.89 7.57H1.68C.757 7.57 0 6.814 0 5.89c0-.926.756-1.682 1.68-1.682h4.21zm6.749 1.682c0-.926.755-1.682 1.68-1.682.925 0 1.681.756 1.681 1.681s-.756 1.681-1.68 1.681h-1.681V5.89zm-.848 0c0 .924-.755 1.68-1.68 1.68A1.685 1.685 0 0 1 8.43 5.89V1.68C8.43.757 9.186 0 10.11 0c.926 0 1.681.756 1.681 1.68v4.21zm-1.681 6.748c.926 0 1.682.756 1.682 1.681S11.036 16 10.11 16s-1.681-.756-1.681-1.68v-1.682h1.68zm0-.847c-.924 0-1.68-.755-1.68-1.68 0-.925.756-1.681 1.68-1.681h4.21c.924 0 1.68.756 1.68 1.68 0 .926-.756 1.681-1.68 1.681h-4.21z"})})},docsRepositoryBase:"https://github.com/intel-sandbox/netai-gym-website/tree/main/new-webpage/",footer:{text:"Intel Labs | Multi-Access Intelligence"},useNextSeoProps:()=>({titleTemplate:"%s"})};t.Z=s},145:function(e,t,n){"use strict";n.r(t);var a=n(1527),s=n(9170),i=n(7059),r=n(6408);n(8143);var o=n(6736);n(6484);let l={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:t}=Object.assign({},(0,o.ah)(),e.components);return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)},pageOpts:{filePath:"pages/references/stable_baselines_3.mdx",route:"/references/stable_baselines_3",headings:[{depth:1,value:"Stable-Baselines3 Docs",id:"stable-baselines3-docs"}],timestamp:1688596736e3,pageMap:[{kind:"Meta",data:{index:{title:"Home",type:"page"},news:{title:"News",type:"page",theme:{typesetting:"article",layout:"full"}},why:{title:"Why",type:"page"},docs:{title:"Documentation",type:"page"},references:{title:"References",type:"page"},contact:{title:"Contact â†—",type:"page",href:"mailto:netaigym@gmail.com",newWindow:!0}}},{kind:"Folder",name:"docs",route:"/docs",children:[{kind:"Meta",data:{index:"Guide","-- API":{type:"separator",title:"API"},overview:"Overview",agent:"Agent",client:"Client",server:"Server",env:"Env","-- Environments":{type:"separator",title:"Environments"},environments:"Environments Overview",mx:"Multi-Access(MX) Traffic Management",cellular_ran_slicing:"Cellular RAN Slicing","-- More":{type:"separator",title:"More"},backup:"Backup"}},{kind:"MdxPage",name:"agent",route:"/docs/agent"},{kind:"MdxPage",name:"backup",route:"/docs/backup"},{kind:"MdxPage",name:"cellular_ran_slicing",route:"/docs/cellular_ran_slicing"},{kind:"Folder",name:"client",route:"/docs/client",children:[{kind:"MdxPage",name:"adapter",route:"/docs/client/adapter"},{kind:"MdxPage",name:"northbound_api",route:"/docs/client/northbound_api"},{kind:"Meta",data:{adapter:"Adapter",northbound_api:"Northbound API"}}]},{kind:"MdxPage",name:"client",route:"/docs/client"},{kind:"Folder",name:"env",route:"/docs/env",children:[{kind:"Meta",data:{southbound_api:"Southbound API",simulator:"Simulator"}},{kind:"MdxPage",name:"simulator",route:"/docs/env/simulator"},{kind:"MdxPage",name:"southbound_api",route:"/docs/env/southbound_api"}]},{kind:"MdxPage",name:"env",route:"/docs/env"},{kind:"MdxPage",name:"environments",route:"/docs/environments"},{kind:"MdxPage",name:"index",route:"/docs"},{kind:"Folder",name:"mx",route:"/docs/mx",children:[{kind:"Meta",data:{mx_traffic_splitting:"Multi-Access(MX) Traffic Splitting",qos_aware_mx_traffic_steering:"QoS-aware MX Traffic Steering"}},{kind:"MdxPage",name:"mx_traffic_splitting",route:"/docs/mx/mx_traffic_splitting"},{kind:"MdxPage",name:"qos_aware_mx_traffic_steering",route:"/docs/mx/qos_aware_mx_traffic_steering"}]},{kind:"MdxPage",name:"overview",route:"/docs/overview"},{kind:"MdxPage",name:"server",route:"/docs/server"}]},{kind:"MdxPage",name:"index",route:"/"},{kind:"MdxPage",name:"news",route:"/news"},{kind:"Folder",name:"references",route:"/references",children:[{kind:"Meta",data:{ns3:"ns-3",gymnasium:"Gymnasium",stable_baselines_3:"Stable-Baselines3",zeromq:"ZeroMQ"}},{kind:"MdxPage",name:"gymnasium",route:"/references/gymnasium"},{kind:"MdxPage",name:"ns3",route:"/references/ns3"},{kind:"MdxPage",name:"stable_baselines_3",route:"/references/stable_baselines_3"},{kind:"MdxPage",name:"zeromq",route:"/references/zeromq"}]},{kind:"Folder",name:"why",route:"/why",children:[{kind:"MdxPage",name:"where_is_data",route:"/why/where_is_data"},{kind:"Meta",data:{where_is_data:"Where Is Data"}}]}],flexsearch:{codeblocks:!0},title:"Stable-Baselines3 Docs"},pageNextRoute:"/references/stable_baselines_3",nextraLayout:i.ZP,themeConfig:r.Z};function d(e){let t=Object.assign({h1:"h1",a:"a",p:"p",img:"img"},(0,o.ah)(),e.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(t.h1,{children:["Stable-Baselines3 ",(0,a.jsx)(t.a,{href:"https://stable-baselines3.readthedocs.io/",children:"Docs"})]}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{src:"https://stable-baselines3.readthedocs.io/en/master/_static/logo.png",alt:"logo"})}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://github.com/DLR-RM/stable-baselines3",children:"Stable Baselines3 (SB3)"})," is a set of reliable implementations of reinforcement learning algorithms in PyTorch. It is the next major version of Stable Baselines."]}),"\n",(0,a.jsxs)(t.p,{children:["Github repository: ",(0,a.jsx)(t.a,{href:"https://github.com/DLR-RM/stable-baselines3",children:"https://github.com/DLR-RM/stable-baselines3"})]}),"\n",(0,a.jsxs)(t.p,{children:["Paper: ",(0,a.jsx)(t.a,{href:"https://jmlr.org/papers/volume22/20-1364/20-1364.pdf",children:"https://jmlr.org/papers/volume22/20-1364/20-1364.pdf"})]}),"\n",(0,a.jsxs)(t.p,{children:["RL Baselines3 Zoo (training framework for SB3): ",(0,a.jsx)(t.a,{href:"https://github.com/DLR-RM/rl-baselines3-zoo",children:"https://github.com/DLR-RM/rl-baselines3-zoo"})]}),"\n",(0,a.jsx)(t.p,{children:"RL Baselines3 Zoo provides a collection of pre-trained agents, scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos."}),"\n",(0,a.jsxs)(t.p,{children:["SB3 Contrib (experimental RL code, latest algorithms): ",(0,a.jsx)(t.a,{href:"https://github.com/Stable-Baselines-Team/stable-baselines3-contrib",children:"https://github.com/Stable-Baselines-Team/stable-baselines3-contrib"})]})]})}t.default=(0,s.j)(l)}},function(e){e.O(0,[8928,9774,2888,179],function(){return e(e.s=3180)}),_N_E=e.O()}]);